{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/RuthStowers/MAT422/blob/main/Homework_1_3_Linear_Regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Te1qp7LWvM8V"
      },
      "source": [
        "# Chapter 1.3 - Linear Regression\n",
        "\n",
        "\n",
        "---\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fj0YbBesvf4A"
      },
      "source": [
        "# 1.3.1 QR Decomposition\n",
        "QR decomposition is a useful procedure to solve the linear least squares\n",
        "problem. QR factorization takes the general form $A = QR$ where $Q$ is the product of the Gram-Schmidt process, and $R$ is an upper triangular matrix as follows."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZBZofZV312JS"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tHrfDPe7DizX",
        "outputId": "6dbe0888-4fb7-4461-ad2a-61e782503dc1"
      },
      "source": [
        "A = np.random.randint(10, size = (3, 3))\n",
        "q, r = np.linalg.qr(A)\n",
        "print('A: \\n', A, '\\n')\n",
        "print('Q: \\n', q, '\\n')\n",
        "print('R: \\n', r, '\\n')"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "A: \n",
            " [[2 2 8]\n",
            " [8 0 8]\n",
            " [7 2 9]] \n",
            "\n",
            "Q: \n",
            " [[-0.18490007  0.73994007 -0.64676167]\n",
            " [-0.73960026 -0.53813824 -0.40422604]\n",
            " [-0.64715023  0.40360368  0.64676167]] \n",
            "\n",
            "R: \n",
            " [[-10.81665383  -1.66410059 -13.22035468]\n",
            " [  0.           2.2870875    5.24684779]\n",
            " [  0.           0.          -2.58704667]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e6_ROJpOEtVo",
        "outputId": "33ee2b9e-dcb1-4ec6-9469-27bda9a354aa"
      },
      "source": [
        "p = (np.matmul(q, r))\n",
        "print(p, '\\n')\n",
        "print(A)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[ 2.00000000e+00  2.00000000e+00  8.00000000e+00]\n",
            " [ 8.00000000e+00 -7.42777761e-16  8.00000000e+00]\n",
            " [ 7.00000000e+00  2.00000000e+00  9.00000000e+00]] \n",
            "\n",
            "[[2 2 8]\n",
            " [8 0 8]\n",
            " [7 2 9]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xsEl1R6VGxPt"
      },
      "source": [
        "As you can see from the above code, $Q$ dotted with $R$ gives us back $A$.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QzwrMTu2G-2m"
      },
      "source": [
        "# 1.3.2 Least-squares Problems\n",
        "We are trying to solve for the system $Ax = b$ where $A$ is an $n$ x $m$ matrix and $n > m$. If $n = m$, then we could just find the matrix inverse.\n",
        "Instead, we find an $Ax$ such that we minimize $\\|Ax-b\\|$."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ofhHJ6dSImK",
        "outputId": "99eda48d-a90c-413a-ba6f-e0e8d102787a"
      },
      "source": [
        "b = np.random.randint(10, size = (3, 1))\n",
        "x = np.matmul(np.matmul(np.linalg.inv(r),np.transpose(q)), b)\n",
        "Ax = np.matmul(A, x)\n",
        "print('solution vector: \\n', x, '\\n')\n",
        "print('b: \\n', b, '\\n')\n",
        "print('Ax: \\n', Ax, '\\n')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "solution vector: \n",
            " [[-0.75]\n",
            " [-0.75]\n",
            " [ 0.75]] \n",
            "\n",
            "b: \n",
            " [[3]\n",
            " [0]\n",
            " [0]] \n",
            "\n",
            "Ax: \n",
            " [[3.]\n",
            " [0.]\n",
            " [0.]] \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hXWJovR4WRyd"
      },
      "source": [
        "As you can see from the above code, we generate a random $b$ vector and use the random $A, Q, R$ values from the previous QR decomposition example. $Ax$ should give a close approximation to $b$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tAkUfaY2XQKs"
      },
      "source": [
        "# 1.3.3 Linear Regression\n",
        "Linear regression seeks to find an affine function to fit a data set as closely as possible. This is a minimization problem and when looked at in matrix form, is the exact same as the least-squares problem. Linear Regression is often used as a method of statistical analysis."
      ]
    }
  ]
}